# üì¶ Installer (dans requirements.txt pour Streamlit Cloud)
# transformers
torch
pandas
streamlit

# üìö Imports
import streamlit as st
import pandas as pd
import torch
import re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO

# ‚öôÔ∏è Initialisation
st.set_page_config(page_title="Analyse NLP Marketing", layout="wide")
st.title("üß† Analyse NLP Marketing avec BERT")

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    return tokenizer, model, device

tokenizer, model, device = load_model()

# üß† Fonctions NLP
def bert_sentiment(text):
    tokens = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    tokens = {k: v.to(device) for k, v in tokens.items()}
    with torch.no_grad():
        output = model(**tokens)
    score = torch.softmax(output.logits, dim=1).cpu().numpy()[0]
    stars = score.argmax() + 1
    return stars, score

def get_sentiment_label(stars):
    if stars <= 2: return "N√©gatif"
    elif stars == 3: return "Neutre"
    return "Positif"

def detect_emotion(text):
    joy = ["aime", "j'adore", "super", "heureux", "cool"]
    anger = ["d√©teste", "nul", "√©nerve", "col√®re"]
    fear = ["peur", "angoisse", "risque"]
    txt = text.lower()
    if any(w in txt for w in joy): return "Joie"
    elif any(w in txt for w in anger): return "Col√®re"
    elif any(w in txt for w in fear): return "Peur"
    return "Neutre"

def detect_intention(text):
    txt = text.lower()
    if any(w in txt for w in ["acheter", "commande", "achat"]): return "Achat"
    if any(w in txt for w in ["probl√®me", "bug", "plainte"]): return "R√©clamation"
    if any(w in txt for w in ["propose", "suggestion", "am√©liorer"]): return "Suggestion"
    if any(w in txt for w in ["info", "comment", "quand"]): return "Demande d'information"
    if any(w in txt for w in ["merci", "parfait", "satisfait"]): return "Satisfaction"
    return "Autre"

def detect_marques(text):
    marques = ["pepsi", "infinix", "nike", "samsung", "orange", "amazon", "dior", "iphone", "carrefour", "huawei",
               "jumia", "apple", "netflix", "spotify", "tecno", "adidas", "air france", "aliexpress", "bmw", "bolt",
               "bouygues", "cdiscount", "coca-cola", "danone", "etsy", "free", "h&m", "hp", "kfc", "microsoft",
               "nestl√©", "peugeot", "ryanair", "sfr", "sncf", "sony", "starbucks", "tesla", "toyota", "uber", "uniqlo",
               "verizon", "volkswagen", "zara", "ebay"]
    return ", ".join([m.capitalize() for m in marques if m in text.lower()]) or "Aucune"

def generer_recommandation(sentiment, emotion):
    if sentiment == "Positif":
        return "üëç Continuer ainsi"
    if sentiment == "N√©gatif":
        if emotion == "Col√®re": return "‚ö†Ô∏è √âviter les contenus irritants"
        if emotion == "Peur": return "üîç Rassurer les clients"
        return "üõ†Ô∏è Am√©liorer l'approche"
    return "ü§î Ajouter plus d‚Äô√©motion"

def resumator(text):
    return text if len(text.split()) <= 5 else " ".join(text.split()[:8]) + "..."

# üì§ Analyse
uploaded_file = st.file_uploader("üìÇ Charger un fichier CSV avec une colonne 'message'", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if "message" not in df.columns:
        st.error("‚ùå Le fichier doit contenir une colonne 'message'.")
    else:
        sentiments, stars_list, emotions, intentions, marques, recommandations, resumes, hashtags = [], [], [], [], [], [], [], []

        for msg in df["message"]:
            stars, _ = bert_sentiment(msg)
            sentiment = get_sentiment_label(stars)
            emotion = detect_emotion(msg)
            intention = detect_intention(msg)
            marque = detect_marques(msg)
            reco = generer_recommandation(sentiment, emotion)
            resume = resumator(msg)
            hash_list = re.findall(r"#\w+", msg)

            sentiments.append(sentiment)
            stars_list.append(stars)
            emotions.append(emotion)
            intentions.append(intention)
            marques.append(marque)
            recommandations.append(reco)
            resumes.append(resume)
            hashtags.append(", ".join(hash_list))

        df["sentiment"] = sentiments
        df["emotion"] = emotions
        df["score_emotion"] = [s * 20 for s in stars_list]
        df["intention"] = intentions
        df["marque"] = marques
        df["recommandation"] = recommandations
        df["resume"] = resumes
        df["hashtags"] = hashtags

        st.success("‚úÖ Analyse termin√©e !")
        st.dataframe(df)

        # üìä Visualisations
        col1, col2 = st.columns(2)
        with col1:
            fig1 = plt.figure(figsize=(5,3))
            sns.countplot(data=df, x="sentiment", palette="cool")
            plt.title("R√©partition des sentiments")
            st.pyplot(fig1)

        with col2:
            fig2 = plt.figure(figsize=(5,3))
            sns.countplot(data=df, x="emotion", palette="Set2")
            plt.title("R√©partition des √©motions")
            st.pyplot(fig2)

        fig3 = plt.figure(figsize=(10,3))
        wc = WordCloud(width=800, height=300, background_color="white", stopwords=STOPWORDS).generate(" ".join(df["message"]))
        plt.imshow(wc, interpolation="bilinear")
        plt.axis("off")
        plt.title("Nuage de mots")
        st.pyplot(fig3)

        # üì• Export CSV
        st.download_button("‚¨áÔ∏è T√©l√©charger les r√©sultats", df.to_csv(index=False).encode("utf-8"), file_name="resultats_nlp.csv", mime="text/csv")
